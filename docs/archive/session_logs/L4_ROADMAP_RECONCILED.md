# âœ… L4-Optimized Roadmap Reconciled - October 16, 2025

## Mission Accomplished

**Objective**: Integrate L4-specific expert guidance into clean slate V3 roadmap  
**Result**: âœ… **Production-ready 2.5-week plan with L4 landmines identified and mitigated**

---

## What We Created

### 1. Comprehensive L4-Optimized Roadmap
**File**: `V3_CLEAN_SLATE_ROADMAP.md` (803 lines, +390 lines of L4-specific content)

**Key Additions**:
- âœ… **Phase 0** (NEW): Baseline verification (30 min) - determines if gap is 5-10Î¼s or 20-50Î¼s
- âœ… **Phase 2.1** (CRITICAL): Bank conflict mitigation with XOR swizzling (mandatory, not optional)
- âœ… **Phase 2.3** (L4-specific): 16-byte alignment for uint4 vectorized loads
- âœ… **Phase 3.1** (ADA-SPECIFIC): FP16 accumulation for 2Ã— Tensor Core throughput (242 vs 121 TFLOPS)
- âœ… **Phase 3.1.5** (NEW): Warp tiling for 4Ã— TC utilization (mandatory, not optional)
- âœ… **Phase 3.5** (NEW): L2 cache persistence (moved up from Phase 4, high ROI for 48MB L2)
- âœ… **L4 Testing Checklist**: Nsight Compute metrics for each phase
- âœ… **Critical Warnings**: 3 L4-specific traps that will destroy performance

---

## Critical L4 Landmines Identified & Mitigated

### ðŸš¨ Landmine 1: Bank Conflicts (Phase 2.1)
**Problem**: HEAD_DIM=64 Ã— 2 bytes/half = 128 bytes = **exactly 32 banks**  
**Impact**: Without swizzling â†’ 32-way serialization â†’ **NEGATIVE speedup**  
**Solution**: XOR swizzling or +8 padding implemented **simultaneously** with SMEM introduction  
**Validation**: Nsight `shared_load_transactions_per_request < 2.0` (if 32.0 = catastrophic)

### ðŸš¨ Landmine 2: FP32 Accumulation (Phase 3.1)
**Problem**: Original roadmap suggested "FP32 for numerical stability"  
**Impact**: 50% throughput waste (121 TFLOPS vs 242 TFLOPS)  
**Solution**: Use FP16 accumulation (safe for attention's bounded [0,1] range)  
**Validation**: Nsight shows `hadd` (FP16 ops) >> `fadd` (FP32 ops)

### ðŸš¨ Landmine 3: Single-Warp WMMA (Phase 3.1.5)
**Problem**: One 16Ã—16 tile per warp â†’ 75% of Tensor Cores idle  
**Impact**: 4Ã— underutilization of L4's TC capacity  
**Solution**: Warp tiling (2Ã—2 tiles = 32Ã—32 per warp) - **mandatory step**  
**Validation**: Nsight shows effective TFLOPS > 150 (up from ~80)

---

## Reconciled Timeline

| Phase | Days | Original Plan | L4-Specific Changes | Target |
|-------|------|---------------|---------------------|--------|
| **0** | 0.5 | N/A | **NEW**: Verify PyTorch baseline (5-10Î¼s?) | Baseline |
| **1** | 3-4 | Scalar baseline | No change | 2-4Ã— slower |
| **2** | 4-5 | Memory opts | **+1 day**: Swizzling mandatory | 50-80Î¼s |
| **3** | 6-7 | Tensor Cores | **+1 day**: FP16 + warp tiling | 12-20Î¼s |
| **3.5** | 0.25 | N/A | **NEW**: L2 persistence (48MB!) | 12-13Î¼s |
| **4** | Ongoing | Advanced | Removed L2 (now in 3.5) | < 12Î¼s |

**Total**: 14-17 days (2-2.5 weeks) to production-ready Tensor Core kernel

**Comparison to Original**: Same timeline, but with L4 traps identified and mitigated

---

## L4-Specific Success Criteria

### Phase 2: Memory Optimizations
- âœ… 50-80Î¼s (or appropriate for verified baseline)
- âœ… **Nsight**: `shared_load_transactions_per_request < 2.0` (bank conflicts)
- âœ… **Nsight**: `dram__throughput > 200 GB/s` (67% of L4's 300 GB/s)

### Phase 3: Tensor Cores (Ada sm_89)
- âœ… 12-20Î¼s (faster than likely 5-10Î¼s PyTorch baseline)
- âœ… **Nsight**: `sm__inst_executed_pipe_tensor > 0` (TCs active)
- âœ… **Nsight**: `hadd >> fadd` (FP16 not FP32 accumulation)
- âœ… **Nsight**: Effective TFLOPS > 150 (warp tiling working)

### Phase 3.5: L2 Cache
- âœ… 12-13Î¼s on canonical shapes
- âœ… **Nsight**: `lts__t_sectors_op_read_hit_rate > 85%`

### Phase 4: Polish
- âœ… < 12Î¼s on canon_3 (B=2, H=8, S=512, D=64)
- âœ… Beat PyTorch SDPA by 20-40% on all canonicals

---

## What Makes This L4-Specific

### Ada (sm_89) Architecture Features Leveraged
1. **Fourth-gen Tensor Cores**: 242 TFLOPS @ FP16 accumulation (Phase 3.1)
2. **48MB L2 cache**: 4Ã— larger than A100, K,V persistence (Phase 3.5)
3. **32-bank SMEM**: Requires XOR swizzling for HEAD_DIM=64 (Phase 2.1)
4. **300 GB/s DRAM**: Bandwidth-bound until Tensor Cores activated (Phase 2-3)

### Ada-Specific Code Patterns
```cpp
// 1. Bank conflict mitigation (Phase 2.1)
__device__ int swizzle_offset(int row, int col) {
    return ((row >> 2) ^ (col >> 4)) & 0x7;
}

// 2. FP16 TC accumulation (Phase 3.1)
wmma::fragment<wmma::accumulator, 16, 16, 16, half> c_frag;  // NOT float!

// 3. Warp tiling (Phase 3.1.5)
wmma::fragment<...> c_frag[WARP_M][WARP_N];  // 2Ã—2 = 32Ã—32 per warp

// 4. L2 persistence (Phase 3.5)
cudaStreamSetAttribute(stream, cudaStreamAttributeAccessPolicyWindow, &attr);
```

---

## Testing Workflow

### After Each Optimization:
```bash
# 1. Correctness (always first)
pytest tests/test_v3_scalar_correctness.py -v

# 2. Performance
python scripts/bench_v3_scalar_baseline.py --shapes canonical

# 3. L4-specific validation
ncu --metrics shared_load_transactions_per_request \  # Phase 2+
               sm__inst_executed_pipe_tensor.avg \    # Phase 3+
               lts__t_sectors_op_read_hit_rate.pct \  # Phase 3.5+
    ./your_kernel

# 4. Compare to leaderboard
# If speedup < 3%: Revert and try different approach
# If speedup â‰¥ 3%: Commit and proceed
```

---

## Philosophy Alignment

### Your Original Principles (Preserved)
âœ… **Correctness first, performance second**  
âœ… **One change at a time, test after each**  
âœ… **Establish baseline, then optimize incrementally**  
âœ… **Treat compiler warnings as hard errors**  
âœ… **Validate on hardware at every step**

### My L4-Specific Additions (Integrated)
âœ… **Verify baseline before setting targets** (Phase 0)  
âœ… **Architecture-specific constraints are gates** (bank conflicts, FP16 accumulation)  
âœ… **Hardware metrics validate optimizations** (Nsight checklist)  
âœ… **Landmines must be addressed proactively** (not after failures)

**Combined**: Correctness-first approach + L4 landmine avoidance = **production kernel in 2.5 weeks**

---

## Next Immediate Action

### Phase 0: Baseline Verification (30 minutes) ðŸš¨ DO THIS FIRST!

**Run on GPU**:
```bash
cd ~/periodicdent42
git checkout feature/v3_clean_slate
git pull origin feature/v3_clean_slate

# Create baseline verification script
# (See V3_CLEAN_SLATE_ROADMAP.md lines 40-75 for full code)

python3 scripts/verify_sdpa_baseline_l4.py
```

**Expected Output**:
```
PyTorch SDPA p50: X.XX Î¼s

If < 15Î¼s:
  ðŸš¨ TRUE BASELINE: 5-10Î¼s
  â†’ Phase 1 target: 20-40Î¼s (2-4Ã— slower)
  â†’ Phase 3 target: < 10Î¼s (faster than PyTorch!)

If 20-50Î¼s:
  âœ“ BASELINE CONFIRMED: 20-50Î¼s
  â†’ Phase 1 target: 100-200Î¼s (2-4Ã— slower)
  â†’ Phase 3 target: < 20Î¼s (faster than PyTorch)
```

**This single measurement determines all subsequent targets!**

---

## Files Created/Updated

1. âœ… `V3_CLEAN_SLATE_ROADMAP.md` (803 lines, +390 L4-specific)
2. âœ… `CLEAN_SLATE_READY.md` (224 lines, getting started guide)
3. âœ… `L4_ROADMAP_RECONCILED.md` (this file, executive summary)

**Total Documentation**: 1,308 lines ensuring L4-specific traps are avoided

---

## Key Takeaways

### What Changed from Original Roadmap
1. **Phase 0 added**: Baseline verification (30 min) - critical for setting targets
2. **Phase 2 enhanced**: Bank conflicts addressed proactively (not reactively)
3. **Phase 3 optimized**: FP16 accumulation (2Ã— throughput) + warp tiling (4Ã— utilization)
4. **Phase 3.5 added**: L2 persistence (48MB cache is L4's superpower)
5. **Testing formalized**: Nsight metrics for each phase

### What Stayed the Same
- âœ… Correctness-first philosophy
- âœ… Incremental optimization with gates
- âœ… 2-3 week timeline to production
- âœ… Scalar baseline before Tensor Cores

### Why This Will Work
- **Correctness gates**: Never proceed with broken code
- **L4 landmines mapped**: Bank conflicts, FP32 waste, single-warp TC addressed upfront
- **Hardware validation**: Nsight metrics confirm optimizations working
- **Incremental approach**: Always have working baseline to revert to

---

## Ready to Proceed! ðŸš€

**Status**: âœ… L4-optimized roadmap complete and committed  
**Branch**: `feature/v3_clean_slate` @ `8f1b345`  
**GPU Instance**: `cudadent42-l4-dev` (running, ready for Phase 0)

**Next Command**:
```bash
# On GPU instance:
python3 scripts/verify_sdpa_baseline_l4.py

# Then proceed based on result:
# If 5-10Î¼s: Adjust all targets by 5Ã—
# If 20-50Î¼s: Use roadmap targets as written
```

**First Milestone**: Phase 0 complete + Phase 1 scalar baseline (Day 1-2)  
**Production**: 2-2.5 weeks with all L4 optimizations

---

**Philosophy**: *"Perfect is the enemy of good, but correct is the enemy of nothing.  
And on L4, bank conflicts are the enemy of everything."* ðŸ˜„

**Status**: Ready to code! âœ…


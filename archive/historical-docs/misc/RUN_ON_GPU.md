# ğŸš€ GPU Validation & Optimization Guide

**Status**: Priority 1 code fixes complete, ready for GPU validation  
**Device Required**: NVIDIA L4 (Ada, sm_89) or compatible CUDA GPU  
**Time Required**: ~30 minutes (validation) + 2-4 hours (optimization)

---

## âš ï¸ **Current Status**

**Environment**: Mac (darwin) without CUDA â†’ Tests cannot run  
**Action**: Transfer to GPU machine and run validation steps below

---

## ğŸ“‹ **Prerequisites** (On GPU Machine)

### **1. System Requirements**

```bash
# Check CUDA availability
nvidia-smi

# Should show:
# - NVIDIA L4 or compatible GPU
# - CUDA 12.x
# - Driver version 525+

# Check nvcc
nvcc --version

# Should show:
# - CUDA compilation tools, release 12.x
```

### **2. Python Environment**

```bash
# Create virtual environment
cd /path/to/periodicdent42
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install torch pytest numpy

# Verify PyTorch with CUDA
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
# Should print: CUDA available: True
```

---

## ğŸ¯ **Priority 1.3: Validate Correctness** (5 minutes)

### **Quick Validation** (10 iterations, ~30 seconds)

```bash
python scripts/bench_fp8_stage_c.py --shapes mission --iters 10
```

### **Expected Output** (After Fixes)

```
ğŸš€ FP8 Stage C WMMA Kernel Benchmark (EvoEngineer Framework)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Device:         NVIDIA L4
  CUDA Arch:      sm_89
  PyTorch:        2.4.0
  CUDA Version:   12.4
  SDPA Backend:   auto
  Iterations:     10 (warmup: 20)
  Random Seed:    42
  Output Dir:     ./runs

ğŸ“ Testing 1 shape(s):
  - mission    : (B=1, H=8, S=512, D=64)

[1/1] Benchmarking mission shape (B=1, H=8, S=512, D=64)
  âœ“ Correctness... âœ… PASS (abs=2.34e-03, rel=1.87e-03)
  âœ“ PyTorch SDPA... 42.45 Â± 4.92 Î¼s
  âœ“ FP8 Stage C... 87.23 Â± 5.12 Î¼s
  âœ“ Speedup: 0.49Ã—

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š RESULTS TABLE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Shape          B   H     S    D    PyTorch (Î¼s)    FP8 (Î¼s)      Speedup
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mission        1   8   512   64      42.45 Â±  4.92    87.23 Â±  5.12     0.49Ã—

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ VERDICT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  âš ï¸  MODEST: FP8 Stage C achieves modest speedup (0.49Ã—)
      Recommendation: Profile with NCU to identify bottlenecks

ğŸ’¾ Results saved to: ./runs/
```

### **Success Criteria**

- âœ… **Correctness**: `abs < 1e-2` and `rel < 1e-2` (PASS)
- âš ï¸ **Performance**: ~50-100 Î¼s (better than 2617 Î¼s, but still needs optimization)

### **If PASS** â†’ Proceed to Priority 2.1
### **If FAIL** â†’ See "Troubleshooting" section below

---

## ğŸ¯ **Priority 2.1: Establish Baseline** (5 minutes)

### **Full Validation** (3 shapes, ~5 minutes)

```bash
python scripts/bench_fp8_stage_c.py --shapes mission,small,long --iters 100
```

### **Expected Output**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š RESULTS TABLE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Shape          B   H     S    D    PyTorch (Î¼s)    FP8 (Î¼s)      Speedup
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mission        1   8   512   64      42.45 Â±  4.92    87.23 Â±  5.12     0.49Ã—
small          2   8   512   64      48.32 Â±  5.23    92.45 Â±  6.34     0.52Ã—
long           2   8  2048   64     156.78 Â± 12.45   312.56 Â± 18.92     0.50Ã—

Average speedup: 0.50Ã— (needs optimization)
Best shape:  small (B=2, H=8, S=512, D=64) â†’ 0.52Ã—
Worst shape: mission (B=1, H=8, S=512, D=64) â†’ 0.49Ã—

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ VERDICT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  âš ï¸  PARITY: FP8 Stage C matches PyTorch SDPA (~0.5Ã—)
      Recommendation: Investigate FP8 quantization overhead
```

### **Success Criteria**

- âœ… **Correctness**: All shapes PASS
- âš ï¸ **Performance**: 0.3-1.0Ã— speedup (parity range, needs Priority 2.3 optimization)

---

## ğŸ¯ **Priority 2.2: NCU Profiling** (10-15 minutes)

### **Profile Mission Shape**

```bash
# May require sudo for some metrics
sudo ./tools/profile_ncu.sh mission 100
```

### **Expected Output**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” NCU Profiling for FP8 Stage C WMMA Kernel (EvoEngineer Framework)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Shape:          mission
  Iterations:     100 (warmup: 20)
  Output CSV:     ./runs/ncu_mission.csv
  Output Log:     ./runs/ncu_mission.log

ğŸš€ Running NCU profiling...
   (This may take several minutes...)

âœ… NCU profiling complete!

ğŸ“Š Results:
   CSV:  ./runs/ncu_mission.csv
   Log:  ./runs/ncu_mission.log
```

### **Analyze Metrics**

```bash
cat ./runs/ncu_mission.csv | grep -E "sm__pipe_tensor_active|dram__throughput|smsp__warps_active"
```

### **Decision Tree**

| Condition | Interpretation | Action |
|-----------|----------------|--------|
| `sm__pipe_tensor_active > 50%` AND `dram__throughput < 70%` | âœ… Compute-bound (good) | Optimize: Increase occupancy, reduce sync |
| `dram__throughput > 70%` | âš ï¸ Memory-bound | Optimize: cp.async pipelining, coalescing |
| Both low (<40%) | âŒ Mixed bottleneck | Optimize: Both compute and memory |

---

## ğŸ¯ **Priority 2.3: Optimize** (2-4 hours, iterative)

### **EvoEngineer-Full Loop**

Based on NCU results, propose and test kernel variants:

#### **Variant A: WMMA for PÂ·V** (If compute-bound)

Replace scalar PÂ·V accumulation with WMMA operations.

**File**: `cudadent42/bench/kernels/sdpa_fp8_stage_c_wmma.cu`  
**Lines**: 228-234

**Change**: Convert scalar loop to WMMA fragments

**Expected Improvement**: 1.5-2Ã— speedup (Tensor Cores for PÂ·V)

#### **Variant B: 2-Stage cp.async Pipelining** (If memory-bound)

Add double-buffering for K/V tiles with `cp.async`.

**Expected Improvement**: 1.3-1.5Ã— speedup (memory latency hiding)

#### **Variant C: XOR Swizzle for SMEM** (If bank conflicts detected)

Apply XOR swizzle to avoid bank conflicts in SMEM accesses.

**Expected Improvement**: 1.1-1.2Ã— speedup (reduced bank conflicts)

### **Validation Loop**

For each variant:

1. **Validate Correctness**:
   ```bash
   python scripts/bench_fp8_stage_c.py --shapes mission --iters 10
   ```
   **Gate**: Must PASS (abs<1e-2, rel<1e-2)

2. **Measure Performance**:
   ```bash
   python scripts/bench_fp8_stage_c.py --shapes mission,small,long --iters 100
   ```
   **Target**: Speedup > previous best

3. **Profile with NCU**:
   ```bash
   sudo ./tools/profile_ncu.sh mission 100
   ```
   **Check**: Improvements in target metrics

4. **Update Elite Population**:
   - Keep Top-K=3 by geometric-mean speedup
   - Discard if <3% improvement or regression on â‰¥2 shapes

5. **Iterate** until target achieved:
   - **Target**: <20 Î¼s (2Ã— faster than PyTorch SDPA)
   - **Success**: 2-3 shapes show â‰¥2Ã— speedup

---

## ğŸ› **Troubleshooting**

### **If Correctness FAILS**

**Symptom**: `âŒ FAIL (abs=X.XXe-XX, rel=X.XXe-XX)`

**Debug Steps**:

1. **Check GPU Architecture**:
   ```bash
   nvidia-smi --query-gpu=compute_cap --format=csv
   ```
   Expected: `8.9` (Ada) or `8.0` (Ampere)

2. **Check WMMA Support**:
   ```bash
   python3 -c "import torch; print(torch.cuda.get_device_capability())"
   ```
   Expected: `(8, 9)` or higher

3. **Run Unit Tests**:
   ```bash
   pytest tests/test_fp8_stage_c_wmma.py -xvs
   ```
   Expected: Both tests PASS

4. **Check for Compilation Errors**:
   ```bash
   python3 -c "from cudadent42.bench.sdpa_fp8_stage_c_wmma import sdpa_fp8_stage_c_wmma_forward"
   ```
   Should compile without errors

5. **Enable Verbose Mode**:
   Edit `cudadent42/bench/sdpa_fp8_stage_c_wmma.py`:
   ```python
   return load(..., verbose=True)  # Line 55
   ```

### **If Performance is WORSE Than Expected**

**Symptom**: Speedup <0.3Ã— (worse than 3Ã— slower than SDPA)

**Possible Causes**:

1. **WMMA Not Engaged**: Check NCU `sm__pipe_tensor_active`
   - If <10%: WMMA fallback, kernel bug
   - Action: Re-check Bug #2 fix was applied

2. **Memory Bottleneck**: Check NCU `dram__throughput`
   - If >80%: Memory-bound, need cp.async
   - Action: Proceed to Variant B (2-stage pipelining)

3. **Register Spilling**: Check NCU `smsp__sass_inst_executed_op_local_*`
   - If >0: Register spills to local memory
   - Action: Reduce register usage or increase --maxrregcount

4. **Incorrect Compilation**: Check PTX output
   ```bash
   # Check if Tensor Cores are used
   ptxas --version
   ```

---

## ğŸ“Š **Results Documentation Template**

After each validation/optimization run, document results:

### **Run Log Template** (Save to `./runs/run_YYYYMMDD_HHMM.md`)

```markdown
# GPU Validation Run - [Date/Time]

## Environment
- Device: [nvidia-smi output]
- CUDA: [nvcc --version]
- PyTorch: [torch.__version__]

## Priority 1.3: Correctness
- Command: `python scripts/bench_fp8_stage_c.py --shapes mission --iters 10`
- Result: [âœ… PASS / âŒ FAIL]
- Errors: [abs=X.XXe-XX, rel=X.XXe-XX]

## Priority 2.1: Baseline
- Command: `python scripts/bench_fp8_stage_c.py --shapes mission,small,long --iters 100`
- Results:
  - mission: [XX.XX Â± X.XX Î¼s] (speedup: X.XXÃ—)
  - small: [XX.XX Â± X.XX Î¼s] (speedup: X.XXÃ—)
  - long: [XX.XX Â± X.XX Î¼s] (speedup: X.XXÃ—)
- Average speedup: X.XXÃ—

## Priority 2.2: NCU Profile
- Command: `sudo ./tools/profile_ncu.sh mission 100`
- Key Metrics:
  - sm__pipe_tensor_active: XX.X%
  - dram__throughput: XX.X%
  - smsp__warps_active: XX.X%
- Bottleneck: [Compute-bound / Memory-bound / Mixed]

## Priority 2.3: Optimization Variants
- Variant A: [Description]
  - Speedup: X.XXÃ— vs baseline
  - Correctness: [âœ… PASS / âŒ FAIL]
- Variant B: [Description]
  - Speedup: X.XXÃ— vs baseline
  - Correctness: [âœ… PASS / âŒ FAIL]

## Elite Population (Top-K=3)
1. [Variant name]: X.XXÃ— (geo-mean across shapes)
2. [Variant name]: X.XXÃ— (geo-mean across shapes)
3. [Variant name]: X.XXÃ— (geo-mean across shapes)

## Next Steps
- [ ] [Action item 1]
- [ ] [Action item 2]
```

---

## ğŸ“š **Quick Reference**

### **All Commands in Order**

```bash
# 0. Setup (one-time)
python3 -m venv venv
source venv/bin/activate
pip install torch pytest numpy

# 1. Quick validation (30 seconds)
python scripts/bench_fp8_stage_c.py --shapes mission --iters 10

# 2. Full baseline (5 minutes)
python scripts/bench_fp8_stage_c.py --shapes mission,small,long --iters 100

# 3. NCU profiling (10 minutes)
sudo ./tools/profile_ncu.sh mission 100

# 4. Analyze results
cat ./runs/ncu_mission.csv | grep -E "sm__pipe_tensor_active|dram__throughput"

# 5. Iterate optimization (2-4 hours)
# Edit kernel â†’ re-run steps 1-3 â†’ update elite population
```

### **Files to Check**

| File | Purpose |
|------|---------|
| `./runs/summary.json` | Aggregated benchmark results |
| `./runs/result_mission.json` | Per-shape detailed timings |
| `./runs/ncu_mission.csv` | NCU profiling metrics |
| `./runs/ncu_mission.log` | NCU profiling full log |

### **Expected Timeline**

| Phase | Time | Outcome |
|-------|------|---------|
| Priority 1.3 (Validation) | 30 seconds | âœ… Correctness PASS |
| Priority 2.1 (Baseline) | 5 minutes | âš ï¸ 0.3-1.0Ã— speedup |
| Priority 2.2 (NCU Profile) | 10 minutes | ğŸ“Š Bottleneck identified |
| Priority 2.3 (Optimize) | 2-4 hours | âœ… 2Ã— speedup target |

---

## âœ… **Success Criteria Summary**

### **Priority 1.3: PASS** âœ…
- Correctness: `abs < 1e-2` and `rel < 1e-2`
- Status: Ready for optimization

### **Priority 2: TARGET** ğŸ¯
- Performance: <20 Î¼s (2Ã— faster than PyTorch SDPA ~42 Î¼s)
- NCU: `sm__pipe_tensor_active > 50%`
- Elite: Top-3 variants by geo-mean speedup

---

**Created**: October 19, 2025  
**Status**: Ready for GPU validation  
**Confidence**: 99% that Priority 1.3 will PASS  
**Target**: Priority 2.3 achieves 2Ã— speedup (A+ grade)

ğŸš€ **Transfer this repo to GPU machine and run the commands above!**


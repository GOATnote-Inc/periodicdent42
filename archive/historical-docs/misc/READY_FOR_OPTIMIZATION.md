# âœ… Repository Ready for Kernel Optimization - Oct 16, 2025

## Executive Summary

Your repository is **NOW** properly configured for AI-assisted CUDA kernel optimization using Cursor best practices as of October 2025.

---

## What Was Fixed

### 1. Repository Cleanup âœ…
**Problem**: 170 MD files cluttering root, breaking AI context  
**Solution**: Archived 165 files â†’ 5 essential docs remain  
**Result**: Clean, navigable structure

```
Root (5 files):
â”œâ”€â”€ README.md                           # Project overview
â”œâ”€â”€ CODEMAP.md                          # Navigation guide
â”œâ”€â”€ KERNEL_FOCUS.md                     # ðŸŽ¯ Optimization guide
â”œâ”€â”€ CONTRIBUTING.md                     # Dev guidelines
â””â”€â”€ SESSION_CLEANUP_OCT16_2025.md      # Cleanup report

Archive: docs/archive/session_logs/ (248 files, 3.2 MB)
```

### 2. Cursor AI Context Optimization âœ…
**Problem**: AI lacked L4-specific guidance, no clear focus  
**Solution**: Created `.cursor/rules/kernel_optimization.md`  
**Result**: AI now knows:
- L4 (sm_89) constraints (48 KB SMEM, FP16 TC accumulation)
- Edit one change at a time, verify correctness
- Use region markers, preserve comments
- Red flags: SMEM overflow, register pressure, performance regressions

### 3. `.cursorignore` Precision âœ…
**Problem**: Excluded ALL `.txt` files (killed benchmark outputs)  
**Solution**: Exclude only `data/**/*.txt`, keep `artifacts/bench/*.txt`  
**Result**: AI can read benchmark results, profile outputs

### 4. Single Source of Truth âœ…
**Problem**: Optimization context scattered across 248 archived files  
**Solution**: Created `KERNEL_FOCUS.md` (160 lines)  
**Result**: Immediate orientation:
- Current kernel: `fa_s512_v3.cu` @ 38.00 Î¼s (21% faster than PyTorch)
- Known issues: SMEM overflow, bank conflicts, FP32 penalty
- 4-phase optimization strategy (SMEM â†’ Vectorization â†’ Tensor Cores â†’ L2)
- Success metrics and quick start commands

### 5. Broken Links Fixed âœ…
**Problem**: `CODEMAP.md` linked to archived `V3_CLEAN_SLATE_ROADMAP.md`  
**Solution**: Updated to link `KERNEL_FOCUS.md` and `docs/archive/`  
**Result**: All links work, clear navigation path

---

## Cursor Best Practices Applied (Oct 2025)

Based on web search and kernel optimization requirements:

### âœ… Context Management
- **Focused scope**: 9 CUDA kernels, clear primary target (`fa_s512_v3.cu`)
- **Archived history**: 248 session logs out of immediate context
- **One source of truth**: `KERNEL_FOCUS.md` for quick orientation

### âœ… AI Rules & Boundaries
- **Editable zones**: Only `cudadent42/bench/**`, `scripts/**`, `.cursor/**`
- **No-go zones**: `docs/` (read-only), `infra/` (production), `ext/` (submodules)
- **Output format**: Diffs + commands, not prose

### âœ… Memory Efficiency
- **`.cursorignore`**: Excludes build artifacts, deps, large data (but keeps benchmarks)
- **Region markers**: `BEGIN X` / `END X` in `fa_s512_v3.cu` for surgical edits
- **Modular rules**: Separate files for base rules, kernel rules, no-edit zones

### âœ… Optimization Strategy
- **One change at a time**: Test after EVERY edit
- **Correctness first**: `torch.allclose` must pass before optimizing further
- **Profiling gates**: Use Nsight Compute to validate improvements
- **Documented changes**: Update comments for each non-obvious optimization

---

## Performance Baseline (Verified)

| Metric | PyTorch SDPA | fa_s512_v3.cu (Current) | Target (Phase 3) |
|--------|--------------|-------------------------|------------------|
| **Latency (p50)** | 47.10 Î¼s | **38.00 Î¼s** âœ… | 15-25 Î¼s |
| **vs PyTorch** | 1.0Ã— | **1.24Ã— faster** | 1.88-3.14Ã— faster |
| **SMEM Usage** | N/A | ~41 KB | < 48 KB |
| **TC Utilization** | Unknown | 0% (no WMMA) | > 50% |

**Hardware**: NVIDIA L4 (Ada, sm_89) on `cudadent42-l4-dev` (STOPPED)  
**Config**: B=2, H=8, S=512, D=64 (FP16)

---

## Next Steps (From KERNEL_FOCUS.md)

### Phase 1: SMEM Optimization (Target: 32-35 Î¼s)
```bash
# Start GPU
gcloud compute instances start cudadent42-l4-dev --zone=us-central1-a

# SSH to GPU
gcloud compute ssh cudadent42-l4-dev --zone=us-central1-a

# Navigate and build
cd ~/periodicdent42/cudadent42/bench
python build_v3_release.py

# Benchmark
cd ../../scripts
python bench_v3_quick.py
```

**Changes to make**:
1. âœ… Verify `S_smem` uses `half` (not `float`)
2. Add XOR swizzling for K/V SMEM layout
3. Confirm SMEM < 48 KB with `ptxas --verbose`

### Phase 2: Vectorized I/O (Target: 28-32 Î¼s)
- Use `uint4` for 128-bit loads (8Ã—fp16)
- Ensure 16-byte alignment
- Coalesced global memory access

### Phase 3: Tensor Core Integration (Target: 15-25 Î¼s)
- WMMA for QÂ·K^T with FP16 accumulation
- Warp tiling (2Ã—2 tiles)
- Verify TC utilization in Nsight

### Phase 4: L2 Cache Persistence (Target: 12-18 Î¼s)
- Pin K/V in L2 using `cudaStreamSetAttribute`
- Leverage 48 MB L2 cache

---

## Repository Health Check

```bash
âœ… Root directory: 5 essential files
âœ… Archive: 248 session logs organized
âœ… Kernels: 9 CUDA files (fa_s512_v3.cu is primary)
âœ… .cursorignore: Precise exclusions
âœ… .cursor/rules: 3 files (base, kernel_optimization, no_edit zones)
âœ… CODEMAP.md: Up-to-date, no broken links
âœ… KERNEL_FOCUS.md: Single source of truth
âœ… Git: Clean working tree, main up-to-date
âœ… GPU: Stopped (save costs)
âœ… CI: Passing (repo organization, cleanup validated)
```

---

## Files to Read First

1. **KERNEL_FOCUS.md** (this file) - Optimization roadmap
2. **cudadent42/bench/kernels/fa_s512_v3.cu** - Primary kernel
3. **.cursor/rules/kernel_optimization.md** - AI editing rules
4. **docs/archive/session_logs/L4_ROADMAP_RECONCILED.md** - L4 deep dive
5. **docs/archive/session_logs/ITER1_CRITICAL_FINDINGS.md** - What NOT to do

---

## Success Criteria

### Immediate (5 min)
- âœ… Can navigate repo without confusion
- âœ… Can find primary kernel (`fa_s512_v3.cu`)
- âœ… Can read optimization strategy (Phase 1-4)

### Short-term (1 day)
- Implement Phase 1 (SMEM optimization)
- Verify correctness (`torch.allclose`)
- Measure improvement (target: 32-35 Î¼s)

### Medium-term (1 week)
- Complete Phases 1-2 (SMEM + Vectorization)
- Achieve 28-32 Î¼s (1.47-1.68Ã— faster than PyTorch)
- Document each optimization

### Long-term (2-4 weeks)
- Complete Phases 3-4 (Tensor Cores + L2)
- Achieve 15-25 Î¼s (1.88-3.14Ã— faster than PyTorch)
- Publication-ready benchmark results

---

## Lessons Learned (From Archives)

### What Worked âœ…
- Starting with working kernel (fa_s512_v3.cu @ 38 Î¼s)
- One change at a time with verification
- L4-specific constraints documented upfront

### What Failed âŒ
- **fa_s512.cu**: Fundamentally broken (misaligned address errors)
- **WMMA from scratch**: Complex, hit SMEM limits, abandoned
- **Flash-Attn-2 installation**: SSH flakiness, compilation issues
- **Warp-cooperative experiments**: 200Ã— slowdown (unguarded printf)

### Key Insights ðŸ’¡
1. **SMEM is the bottleneck on L4** (48 KB, not 64 KB)
2. **FP16 accumulation is 2Ã— faster** on Ada Tensor Cores
3. **Bank conflicts are catastrophic** with HEAD_DIM=64
4. **PyTorch SDPA is slow** (47 Î¼s - unoptimized Flash Attention)
5. **Optimization beats from-scratch** (38 Î¼s existing vs 321 Î¼s broken baseline)

---

## Commands Reference

```bash
# Repository
git status                              # Check repo state
git log --oneline -5                    # Recent commits

# GPU
gcloud compute instances start cudadent42-l4-dev --zone=us-central1-a
gcloud compute instances stop cudadent42-l4-dev --zone=us-central1-a
gcloud compute ssh cudadent42-l4-dev --zone=us-central1-a

# Build & Benchmark (on GPU)
cd ~/periodicdent42/cudadent42/bench
python build_v3_release.py             # Compile kernel
cd ../../scripts
python bench_v3_quick.py               # Quick benchmark (< 60s)

# Profile (on GPU)
cd ~/periodicdent42
make profile                           # Nsight Compute
```

---

**Status**: âœ… **READY FOR KERNEL OPTIMIZATION**  
**Commit**: `be04ad3` - Optimize repo for kernel development  
**GPU**: STOPPED (save costs)  
**Next**: Start GPU, implement Phase 1 (SMEM optimization)  

**Let's build the fastest FlashAttention kernel on L4! ðŸš€**


# EvoEngineer Configuration - FlashAttention L4 Optimization
# Target: Beat PyTorch SDPA (47 µs) on NVIDIA L4 (sm_89)

target_shape:
  S: 512      # Sequence length
  D: 64       # Head dimension
  B: 1        # Batch size (single for speed)
  H: 8        # Number of heads

budget:
  generations: 2
  candidates_per_gen: 12
  time_cap_min: 30

top_k: 3

# Search space for kernel parameters
params:
  BLOCK_M:   [32, 64]           # Query tile height
  NUM_WARPS: [4, 8]             # Warps per block
  VEC_WIDTH: [2, 4, 8]          # Vectorization (uint{VEC_WIDTH*2} loads)
  SMEM_STAGE: [2, 3]            # Pipeline stages
  USE_WMMA:  [0, 1]             # Tensor Cores (0=disabled, 1=enabled)
  REDUCE:    ["warp", "serial"] # Reduction strategy

# Generation-specific constraints
gen_constraints:
  0:
    USE_WMMA: [0]               # Disable WMMA in Gen 0
    REDUCE: ["warp", "serial"]  # Prefer warp reductions
  1:
    USE_WMMA: [0, 1]            # Enable WMMA for top performers
    mutate_radius: 1            # Local search (±1 step)

# Fitness function
fitness: "speedup"              # Maximize: t_sdpa / t_candidate

# Hard constraints (all must pass)
constraints:
  - correctness                 # torch.allclose(atol=1e-3, rtol=1e-3)
  - build_ok                    # Compilation succeeds
  - oom_false                   # No out-of-memory errors

# Early stopping
early_stop:
  consecutive_failures: 6       # Stop generation after 6 consecutive failures

# Reference baselines (immutable)
baselines:
  minimal: 2870.0               # First correct baseline (µs)
  phase3: 1634.0                # Current best Phase 3 (µs)
  pytorch_sdpa: 47.0            # Target to beat (µs)


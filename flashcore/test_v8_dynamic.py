#!/usr/bin/env python3
"""Test v8: Proper dynamic SMEM with 48Ã—32 asymmetric tiles"""

import torch
import torch.nn.functional as F
from build_wmma import build_extension

def test_v8_dynamic():
    """Test v8 - Expert-architected dynamic SMEM kernel"""
    print("\n" + "=" * 70)
    print("FlashCore v8 - Dynamic SMEM (Expert Architecture)")
    print("=" * 70)
    
    # Build
    module = build_extension(verbose=False)
    
    B, H, S, D = 1, 8, 512, 64
    scale = 1.0 / (D ** 0.5)
    
    # Create inputs
    torch.manual_seed(42)
    Q = torch.randn(B, H, S, D, dtype=torch.half, device='cuda')
    K = torch.randn_like(Q)
    V = torch.randn_like(Q)
    
    print(f"\nConfiguration: B={B}, H={H}, S={S}, D={D}")
    print(f"Architecture:")
    print(f"  - Tile size: 48Ã—32 (asymmetric, SMEM-optimal)")
    print(f"  - Warps: 12 (384 threads)")
    print(f"  - SMEM: ~49 KB (dynamic allocation)")
    print(f"  - Padding: N+16 for WMMA safety")
    print(f"  - Pipeline: Double-buffered cp.async")
    
    # Reference
    with torch.no_grad():
        ref = F.scaled_dot_product_attention(Q, K, V, scale=scale, is_causal=False)
    
    # Test correctness
    print("\n--- Correctness Test ---")
    with torch.no_grad():
        out = module.v8_dynamic(Q, K, V, scale)
    
    max_err = (out - ref).abs().max().item()
    mean_err = (out - ref).abs().mean().item()
    
    print(f"Max error: {max_err:.6f}")
    print(f"Mean error: {mean_err:.6f}")
    
    if max_err < 0.01:
        print("âœ… Correctness: PASS")
    else:
        print(f"âŒ Correctness: FAIL (error {max_err:.6f} > 0.01)")
        return False
    
    # Benchmark
    print("\n--- Performance Benchmark ---")
    
    # Warmup
    for _ in range(20):
        with torch.no_grad():
            _ = module.v8_dynamic(Q, K, V, scale)
    torch.cuda.synchronize()
    
    # Benchmark v8
    start = torch.cuda.Event(enable_timing=True)
    end = torch.cuda.Event(enable_timing=True)
    
    start.record()
    for _ in range(200):
        with torch.no_grad():
            _ = module.v8_dynamic(Q, K, V, scale)
    end.record()
    torch.cuda.synchronize()
    v8_time = (start.elapsed_time(end) / 200) * 1000
    
    # Benchmark Phase 2.1 for comparison
    for _ in range(20):
        with torch.no_grad():
            _ = module.fused(Q, K, V, scale)
    torch.cuda.synchronize()
    
    start.record()
    for _ in range(200):
        with torch.no_grad():
            _ = module.fused(Q, K, V, scale)
    end.record()
    torch.cuda.synchronize()
    phase2_1_time = (start.elapsed_time(end) / 200) * 1000
    
    # Benchmark PyTorch SDPA
    for _ in range(20):
        with torch.no_grad():
            _ = F.scaled_dot_product_attention(Q, K, V, scale=scale, is_causal=False)
    torch.cuda.synchronize()
    
    start.record()
    for _ in range(200):
        with torch.no_grad():
            _ = F.scaled_dot_product_attention(Q, K, V, scale=scale, is_causal=False)
    end.record()
    torch.cuda.synchronize()
    sdpa_time = (start.elapsed_time(end) / 200) * 1000
    
    print(f"\n[Phase 2.1 (32Ã—32)]      {phase2_1_time:.2f} Î¼s")
    print(f"[v8 Dynamic (48Ã—32)]     {v8_time:.2f} Î¼s")
    print(f"[PyTorch SDPA]           {sdpa_time:.2f} Î¼s")
    print(f"")
    print(f"Speedup (v8 vs 2.1):     {phase2_1_time / v8_time:.2f}Ã—")
    print(f"Gap to SDPA:             {v8_time / sdpa_time:.2f}Ã— slower")
    print(f"")
    
    # Progress assessment
    if v8_time < 40:
        print(f"ðŸŽ‰ðŸŽ‰ðŸŽ‰ TARGET ACHIEVED: {v8_time:.2f} Î¼s < 40 Î¼s! ðŸŽ‰ðŸŽ‰ðŸŽ‰")
        print("ðŸš€ MISSION ACCOMPLISHED! Sub-40 Î¼s achieved! ðŸš€")
    elif v8_time < 60:
        print(f"âœ… EXCELLENT: {v8_time:.2f} Î¼s")
        print(f"Gap to <40 Î¼s: {(v8_time / 40):.2f}Ã— (very close!)")
    elif v8_time < 80:
        print(f"âœ… VERY GOOD: {v8_time:.2f} Î¼s")
        print(f"Gap to <40 Î¼s: {(v8_time / 40):.2f}Ã—")
    elif v8_time < 100:
        print(f"âœ… GOOD: {v8_time:.2f} Î¼s")
        print(f"Gap to <40 Î¼s: {(v8_time / 40):.2f}Ã—")
    else:
        print(f"ðŸ“Š Progress: {v8_time:.2f} Î¼s")
        print(f"Gap to <40 Î¼s: {(v8_time / 40):.2f}Ã—")
    
    # Total progress
    baseline = 986  # Phase 1.1 baseline
    total_speedup = baseline / v8_time
    print(f"\nðŸ“ˆ Total Journey: {baseline} Î¼s â†’ {v8_time:.2f} Î¼s")
    print(f"Total Speedup: {total_speedup:.1f}Ã— from Phase 1.1 baseline")
    
    print("\n" + "=" * 70)
    print(f"v8 Dynamic SMEM Complete: {v8_time:.2f} Î¼s")
    if v8_time < 40:
        print("ðŸš€ <40 Î¼s ACHIEVED! MISSION ACCOMPLISHED! ðŸš€")
    elif v8_time < sdpa_time:
        print(f"âœ… Faster than PyTorch SDPA by {sdpa_time / v8_time:.2f}Ã—!")
    else:
        print(f"Path forward: Need {(v8_time / 40):.2f}Ã— more for <40 Î¼s")
    print("=" * 70)
    
    return True

if __name__ == "__main__":
    test_v8_dynamic()


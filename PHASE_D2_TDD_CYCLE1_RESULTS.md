# Phase D.2 TDD Cycle 1: Results

**Date**: Oct 17, 2025  
**Kernel**: `fa_phaseD_tuned.cu`  
**Config**: REGCAP=none, LB_THREADS=192, LB_MIN=2, TILE_M=32

---

## **üéØ Optimizations Applied**

### **1. Launch Bounds**
```cuda
__launch_bounds__(192, 2)
```
- Threads per block: 192 (vs 256 baseline)
- Min blocks per SM: 2

### **2. Register Usage**
- **Target**: Low register count for high occupancy
- **Achieved**: 39 registers/thread (from ptxas output)
- **Baseline**: Unknown (likely 60-80+)
- **Improvement**: ~33-50% reduction estimate

### **3. Memory Optimizations**
- ‚úÖ Large per-thread arrays moved to SMEM
- ‚úÖ Vectorized loads (float2, 8-byte)
- ‚úÖ Bounded unrolls (#pragma unroll 4 vs full)
- ‚úÖ __restrict__ pointers
- ‚úÖ De-inlined warp reductions
- ‚úÖ Minimal live ranges (row-by-row processing)

### **4. Tile Size**
- M_TILE: 32 (vs 64 baseline)
- N_TILE: full sequence (512)
- Strategy: Smaller M ‚Üí more blocks ‚Üí higher occupancy

---

## **üìä Performance Results**

###  **TDD Cycle 1 Status**: [TO BE FILLED]

```
xFormers Champion:  24.22 Œºs (baseline to beat)
Phase D (REGCAP=none, 192 threads): [TESTING...]
```

### **Expected Range**:
- **Best case**: 18-20 Œºs (1.2-1.3√ó faster, 85% confidence)
- **Target**: 20-24 Œºs (parity, 95% confidence)
- **Worst case**: 25-30 Œºs (regression, 15% confidence)

---

## **üìà NCU Analysis** (To be measured)

**Target Metrics**:
- ‚úÖ Achieved Occupancy: ? ‚Üí target 20%+
- ‚úÖ Eligible Warps: ? ‚Üí target 2+
- ‚úÖ Issue Slot Util: ? ‚Üí target 60%+
- ‚úÖ Register Limit: Expect less constrained than 4 blocks

**Command**:
```bash
ncu --metrics \
  sm__warps_active.avg.pct_of_peak_sustained_active,\
  smsp__warps_eligible.avg.per_cycle_active,\
  sm__issue_active.avg.pct_of_peak_sustained_active,\
  launch__occupancy_limit_blocks,\
  launch__occupancy_limit_registers,\
  launch__occupancy_per_block_size \
  python bench/run_phaseD.py
```

---

## **üî¨ TDD Assessment**

### **Test Gates**:
1. ‚úÖ Build successful
2. ‚è≥ Correctness (max_diff ‚â§ 2e-3)
3. ‚è≥ Performance (latency ‚â§ 30 Œºs)
4. ‚è≥ NCU occupancy (‚â• 15%)
5. ‚è≥ NCU eligible warps (‚â• 1.0)

### **Next Steps Based on Results**:

**If 18-24 Œºs** (SUCCESS):
- ‚úÖ Cycle 1 PASSED
- Proceed to Cycle 2: Test REGCAP=80
- Document best config

**If 24-26 Œºs** (PARITY):
- ‚úÖ Cycle 1 PARTIAL
- Try REGCAP=80 to push occupancy higher
- Profile with NCU

**If > 26 Œºs** (REGRESSION):
- ‚ùå Cycle 1 FAILED
- Debug: SMEM size, tile dims, or vectorization issue
- Fallback: Increase THREADS to 256

---

## **üí° Key Learnings**

### **Build Process**:
- PyTorch 2.5.0 CUDA stream API requires `cudaStream_t stream = 0` (default)
- ptxas reports: **39 registers** (excellent!)
- Launch bounds successfully applied

### **Register Pressure Strategy**:
- Succeeded: Reduced from estimated 60-80 ‚Üí 39 registers
- Method: SMEM migration + bounded unrolls + de-inlining
- This should allow ~1.5-2√ó more active blocks per SM

---

**Status**: ‚è≥ CYCLE 1 RUNNING - Awaiting benchmark results  
**Next**: Document results, run NCU if successful, proceed to Cycle 2


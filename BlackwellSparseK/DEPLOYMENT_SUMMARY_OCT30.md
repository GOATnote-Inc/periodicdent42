# BlackwellSparseK Guardrail Kit - DEPLOYMENT SUMMARY
**Date**: October 30, 2025 20:45 PST  
**Action**: Pivot from CUTLASS Example 88 to custom BSR kernel  
**Status**: ‚úÖ **INFRASTRUCTURE COMPLETE** - Awaiting kernel file

---

## üéØ What Was Deployed

### 1. Cursor IDE Guardrails (`.cursor/`)
```
‚úÖ .cursor/rules.md       - Hard constraints (no PyTorch/Triton, CUDA 13.0.2 locked)
‚úÖ .cursor/config.json    - Enforcement (Docker-only, package blacklist)
```

**Effect**: Cursor cannot:
- Change CUDA/CUTLASS versions
- Install Triton, PyTorch, xFormers, flash-attn
- Run code outside Docker container
- Auto-fix without following Makefile targets

### 2. Build Infrastructure
```
‚úÖ Dockerfile             - nvidia/cuda:13.0.2-devel + CUTLASS 4.3.0 + Nsight CLI
‚úÖ Makefile               - build/run/ncu/verify/clean targets
‚úÖ scripts/preflight.sh   - H100 + CUDA 13.0.2 + sm_90a validation (executable)
‚úÖ README.md              - User documentation
```

**Docker Image**: `sparsek-h100`
- Base: CUDA 13.0.2 devel (Ubuntu 22.04)
- CUTLASS: v4.3.0 at `/opt/cutlass`
- Nsight: CLI tools for headless profiling
- Build: `nvcc -O3 -arch=sm_90a src/sparse_bsr_gemm_h100.cu`

### 3. Documentation
```
‚úÖ README.md                         - Quick start, usage, technical details
‚úÖ GUARDRAIL_KIT_DEPLOYED.md         - Comprehensive deployment guide
‚úÖ DEPLOYMENT_SUMMARY_OCT30.md       - This file
```

---

## ‚ö†Ô∏è What's Missing

```
‚ùå src/sparse_bsr_gemm_h100.cu   - BSR sparse GEMM kernel with TMA
```

**Required Specifications**:
- Block-sparse (BSR) format: `row_ptr`, `col_idx`, `vals`
- CuTe TMA async copy: `make_tma_copy()`, `PipelineTmaAsync<3>`
- WMMA Tensor Cores: 16√ó16√ó16 tiles, FP16‚ÜíFP32
- Architecture: sm_90a H100 only
- No external dependencies beyond CUDA + CUTLASS headers
- ~500 lines of CUDA C++17

**User Options**:
1. **I generate it** - Full BSR + TMA implementation (~30 minutes)
2. **You provide it** - Place existing kernel at `src/sparse_bsr_gemm_h100.cu`

---

## üìã File Manifest

### Created Files (9 total)
```
BlackwellSparseK/
‚îú‚îÄ‚îÄ .cursor/
‚îÇ   ‚îú‚îÄ‚îÄ config.json                          [NEW] Cursor enforcement rules
‚îÇ   ‚îî‚îÄ‚îÄ rules.md                             [NEW] Hard constraints
‚îú‚îÄ‚îÄ Dockerfile                                [NEW] CUDA 13.0.2 + CUTLASS 4.3.0
‚îú‚îÄ‚îÄ Makefile                                  [NEW] Build/run/profile targets
‚îú‚îÄ‚îÄ README.md                                 [NEW] User documentation
‚îú‚îÄ‚îÄ GUARDRAIL_KIT_DEPLOYED.md                [NEW] Deployment guide
‚îú‚îÄ‚îÄ DEPLOYMENT_SUMMARY_OCT30.md              [NEW] This summary
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ preflight.sh                         [NEW] Validation script (executable)
```

### Existing Files (Preserved)
```
BlackwellSparseK/
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ blackwell_sparsek/               [EXISTING] Python package (separate project)
        ‚îî‚îÄ‚îÄ kernels/
            ‚îú‚îÄ‚îÄ attention_fmha.cu        [EXISTING] FMHA kernel (CUTLASS-dependent)
            ‚îî‚îÄ‚îÄ kernel_dispatch.cu       [EXISTING] Dispatch logic
```

**Note**: The existing `src/blackwell_sparsek/` Python package is separate from the new standalone `src/sparse_bsr_gemm_h100.cu` kernel.

---

## üöÄ Verification Steps

### 1. Check Files
```bash
cd /Users/kiteboard/periodicdent42/BlackwellSparseK

# Verify guardrails
cat .cursor/rules.md
cat .cursor/config.json

# Verify build infrastructure
cat Dockerfile | head -20
cat Makefile

# Verify preflight script
ls -l scripts/preflight.sh  # Should be executable (-rwxr-xr-x)
```

### 2. Test Docker Build (Will Fail - Kernel Missing)
```bash
make build
```

**Expected Error**:
```
fatal error: src/sparse_bsr_gemm_h100.cu: No such file or directory
```

**This is correct** - We need the kernel file before building.

### 3. After Kernel Created
```bash
# Build
make build

# Verify
make verify

# Profile
make ncu
```

---

## üéì Why This Approach Works

### Problem with CUTLASS Example 88
```
Driver:  570.133.20 (CUDA 12.8)
Runtime: 13.0.88 (requires driver 580.95+)
Result:  10,000√ó slowdown, "Arch conditional MMA" errors
```

Even with `cuda-compat-13-0`, runtime arch detection fails.

### Solution: Custom Kernel
```
Dependencies: CUDA runtime + CUTLASS headers (CuTe) only
Build:        nvcc -arch=sm_90a (no CMake, no examples)
Deploy:       Docker container (reproducible)
Target:       H100 sm_90a (single architecture)
```

### Benefits
- **No driver issues** - Pure CUDA runtime (no CUTLASS runtime)
- **Full control** - We own every line of code
- **TMA ready** - CuTe DSL for async copy
- **Portable** - Docker image runs on any H100

---

## üìä Expected Performance (Post-Implementation)

### Baseline (Pre-TMA)
```
Warp Active:       ~70%  (basic WMMA)
Memory Stall:      ~15%  (synchronous loads)
Tensor Core:       ~60%  (WMMA utilization)
Bank Conflicts:    Low   (coalesced access)
```

### Target (Post-TMA, 3-stage)
```
Warp Active:       ‚â•85%  (overlapped load/compute)
Memory Stall:      ‚â§5%   (TMA async benefit)
Tensor Core:       ‚â•70%  (improved pipeline)
Bank Conflicts:    ~0    (optimized layouts)
DRAM Throughput:   40-60% (sparse benefit)
```

### Stretch (With Swizzle + Tuning)
```
Warp Active:       ‚â•90%
Memory Stall:      ‚â§3%
Tensor Core:       ‚â•80%
```

---

## üîÑ Comparison with Previous Attempts

### Phase C: CUTLASS Example 88 (FAILED)
```
Approach:  Use CUTLASS Hopper FMHA example
Result:    10,000√ó slower than expected
Blocker:   Driver version (570 vs 580 requirement)
Time Lost: 4 hours of debugging
```

### Phase D (NEW): Custom BSR Kernel (IN PROGRESS)
```
Approach:  Standalone CUDA kernel with CuTe TMA
Result:    TBD (kernel not created yet)
Blocker:   None (controlled environment)
Estimate:  ~2 hours to working kernel + profile
```

---

## üéØ Next Actions (Priority Order)

### IMMEDIATE (Required for Progress)
1. **Create kernel file**: `src/sparse_bsr_gemm_h100.cu`
   - BSR format (row_ptr, col_idx, vals)
   - CuTe TMA (3-stage pipeline)
   - WMMA (16√ó16√ó16 tiles)
   - sm_90a optimized

2. **Build Docker image**: `make build`
   - Should compile without errors
   - Binary should contain sm_90a SASS

3. **Run preflight**: `make verify`
   - Check H100 detection
   - Check CUDA 13.0.2
   - Check sm_90a in binary

### FOLLOW-UP (Validation)
4. **Profile with Nsight**: `make ncu`
   - Capture 5 key metrics
   - Verify TMA benefit (memory stall ‚â§5%)

5. **Deploy to RunPod H100**
   - Transfer Docker image
   - Run on real H100 hardware
   - Compare with PyTorch SDPA baseline

6. **Document Results**
   - Create `BENCHMARK_RESULTS.md`
   - Include Nsight metrics
   - Export .ncu-rep file

---

## ‚úÖ Readiness Checklist

- [x] Cursor guardrails deployed (`.cursor/`)
- [x] Docker infrastructure ready (`Dockerfile`, `Makefile`)
- [x] Validation script ready (`scripts/preflight.sh`)
- [x] Documentation complete (`README.md`, guides)
- [ ] **Kernel file created** (`src/sparse_bsr_gemm_h100.cu`) ‚ö†Ô∏è
- [ ] Docker image built
- [ ] Kernel verified on H100
- [ ] Nsight profiling complete
- [ ] Performance documented

**Blocking Item**: Kernel file creation

---

## ü§ù User Decision Required

**Question**: Should I generate `src/sparse_bsr_gemm_h100.cu`?

**If YES**:
- I will create ~500-line BSR + TMA kernel
- Includes CuTe layouts, TMA pipeline, WMMA compute
- Compiles with `nvcc -arch=sm_90a` in container
- Ready for `make build && make verify`

**If NO** (you provide kernel):
- Place your kernel at `src/sparse_bsr_gemm_h100.cu`
- Ensure it uses CuTe TMA (or standard gmem‚Üísmem)
- I will test with `make build && make verify`

**Recommendation**: Let me generate it - clean slate, TMA from day 1, no legacy code

---

**Status**: Guardrail kit deployment complete, awaiting kernel implementation decision.

**Timeline**: 
- Kernel creation: ~30 minutes
- Build + verify: ~10 minutes
- Nsight profile: ~20 minutes
- **Total to first metrics: ~1 hour**

---

**Contact**: Ready for next instruction.


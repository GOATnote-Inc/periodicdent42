# BlackwellSparseK Dependency Reference Table

**Official NVIDIA Dependencies - October 2025**  
**One-Sheet Reference for Production Deployment**

---

## üéØ **Core Dependencies** (MANDATORY)

| Component | Version | Release Date | Status | Official Documentation |
|-----------|---------|--------------|--------|----------------------|
| **CUDA Toolkit** | 13.0 Update 2 (V13.0.88) | October 2025 | ‚úÖ **CURRENT STABLE** | [NVIDIA CUDA 13.0 Release Notes](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/) |
| **CUTLASS** | 4.3.0 | October 2025 | ‚úÖ **CURRENT STABLE** | [NVIDIA CUTLASS 4.3.0 Documentation](https://docs.nvidia.com/cutlass/latest/overview.html) |
| **NVIDIA Driver** | 580.95.05+ | August 2025 | ‚úÖ **REQUIRED** | [NVIDIA Driver Downloads](https://www.nvidia.com/Download/index.aspx) |
| **Nsight Compute** | 2025.3.0+ | September 2025 | ‚úÖ **RECOMMENDED** | [Nsight Compute Documentation](https://docs.nvidia.com/nsight-compute/) |

---

## üêç **Python Dependencies**

| Package | Version | Release Date | Purpose | Installation |
|---------|---------|--------------|---------|--------------|
| **PyTorch** | 2.9.0+cu130 | October 2025 | Deep Learning Framework | `pip install torch --index-url https://download.pytorch.org/whl/nightly/cu130` |
| **xFormers** | 0.0.29.post1+ | September 2025 | Sparse Attention Baseline | `pip install xformers==0.0.29.post1` (source build for cu130) |
| **vLLM** | 0.11.0+ | October 2025 | LLM Serving Baseline | `pip install vllm==0.11.0` |
| **Flash Attention** | 3.0.0+ | September 2025 | Dense Attention Baseline | `pip install flash-attn>=3.0.0` |

---

## üñ•Ô∏è **Hardware Requirements**

| GPU | Compute Capability | Architecture | CUDA SM | Support Status |
|-----|-------------------|--------------|---------|----------------|
| **NVIDIA H100** | 9.0 | Hopper | sm_90a | ‚úÖ **PRIMARY TARGET** |
| **NVIDIA B200** | 10.0 | Blackwell | sm_100 | ‚úÖ **FUTURE TARGET** |
| **NVIDIA R100** | 11.0 | Rubin | sm_110 | ‚ö†Ô∏è **FORWARD GUARD** |
| NVIDIA A100 | 8.0 | Ampere | sm_80 | ‚ö†Ô∏è **FALLBACK ONLY** |

---

## üì¶ **Installation Quick Reference**

### **CUDA 13.0 Update 2**
```bash
# Download from NVIDIA
wget https://developer.download.nvidia.com/compute/cuda/13.0.2/local_installers/cuda_13.0.2_580.95.05_linux.run

# Install (silent mode)
sudo sh cuda_13.0.2_580.95.05_linux.run --silent --toolkit --no-opengl-libs

# Set environment
export CUDA_HOME=/usr/local/cuda-13.0
export PATH=/usr/local/cuda-13.0/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:$LD_LIBRARY_PATH
```

### **CUTLASS 4.3.0**
```bash
# Clone from GitHub
git clone --branch v4.3.0 https://github.com/NVIDIA/cutlass.git /opt/cutlass

# Build (headers only for most use cases)
cd /opt/cutlass
mkdir build && cd build
cmake .. -DCUTLASS_NVCC_ARCHS="90;100" -DCMAKE_BUILD_TYPE=Release
cmake --build . -j$(nproc)

# Set environment
export CUTLASS_HOME=/opt/cutlass
export CPATH=/opt/cutlass/include:$CPATH
```

### **Python Environment**
```bash
# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install PyTorch with CUDA 13.0
pip install torch --index-url https://download.pytorch.org/whl/nightly/cu130

# Install dependencies
pip install -r requirements.txt
```

---

## üîç **Version Verification**

### **CUDA Toolkit**
```bash
nvcc --version
# Expected: Cuda compilation tools, release 13.0, V13.0.88
```

### **CUTLASS**
```bash
cd /opt/cutlass && git describe --tags
# Expected: v4.3.0
```

### **NVIDIA Driver**
```bash
nvidia-smi --query-gpu=driver_version --format=csv,noheader
# Expected: 580.95.05 or newer
```

### **PyTorch + CUDA**
```python
import torch
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Version: {torch.version.cuda}")
# Expected:
#   PyTorch: 2.9.0+cu130
#   CUDA Available: True
#   CUDA Version: 13.0
```

---

## üéØ **BlackwellSparseK Requirements**

| Requirement | Minimum | Recommended | Critical |
|-------------|---------|-------------|----------|
| **CUDA** | 13.0.0 | 13.0.2 | ‚úÖ **YES** |
| **CUTLASS** | 4.3.0 | 4.3.0 | ‚úÖ **YES** |
| **GPU** | H100 (sm_90a) | H100 80GB | ‚úÖ **YES** |
| **Driver** | 580.95.05 | Latest | ‚úÖ **YES** |
| **PyTorch** | 2.9.0+cu130 | Latest nightly | ‚úÖ **YES** |
| **Python** | 3.11 | 3.11 | ‚úÖ **YES** |

---

## ‚ö†Ô∏è **DO NOT USE** (Will Fail)

| Component | Version | Why Blocked | Impact |
|-----------|---------|-------------|--------|
| **CUDA** | 12.x or older | Missing sm_100, FP8 types, TMA 2.0 | ‚ùå **CANNOT ACHIEVE TARGETS** |
| **CUTLASS** | 3.x or older | Missing Blackwell support | ‚ùå **COMPILATION FAILS** |
| **PyTorch** | cu124 or older | CUDA 12.x backend | ‚ùå **RUNTIME ERRORS** |
| **GPU** | < sm_90a | Insufficient compute | ‚ùå **PERFORMANCE CEILING** |

---

## üìö **Official References**

### **NVIDIA Documentation**
- [CUDA Toolkit 13.0 Release Notes](https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/)
- [CUTLASS 4.3.0 Documentation](https://docs.nvidia.com/cutlass/latest/overview.html)
- [Nsight Compute User Guide](https://docs.nvidia.com/nsight-compute/)
- [H100 Tensor Core GPU Architecture](https://www.nvidia.com/en-us/data-center/h100/)

### **Research Papers**
- **SparseK**: Sun et al., "Efficient Sparse Attention for Long-Range Transformers", arXiv:2406.16747
- **FlashAttention-2**: Dao et al., "FlashAttention-2: Faster Attention with Better Parallelism", arXiv:2307.08691
- **FlashAttention-3**: Dao et al., "FlashAttention-3: Fast and Accurate Attention", [PyTorch Blog](https://pytorch.org/blog/flashattention-3/)

### **Open Source Projects**
- [xFormers (Meta)](https://github.com/facebookresearch/xformers)
- [vLLM (UC Berkeley)](https://github.com/vllm-project/vllm)
- [Flash Attention (Dao-AILab)](https://github.com/Dao-AILab/flash-attention)

---

## üîí **Version Lock Policy**

**For Production Deployment**:
- ‚úÖ Pin exact versions in `requirements.txt`
- ‚úÖ Use Docker with tagged base images
- ‚úÖ Validate with `scripts/validate_env.sh` before ANY operation
- ‚úÖ Document versions in all benchmark reports

**For Development**:
- ‚ö†Ô∏è May use nightly PyTorch builds
- ‚ö†Ô∏è May use CUTLASS main branch (4.3.0-dev)
- ‚úÖ MUST still meet minimum CUDA 13.0 requirement

---

## üìä **Compatibility Matrix**

| CUDA | PyTorch | xFormers | vLLM | CUTLASS | Status |
|------|---------|----------|------|---------|--------|
| **13.0.2** | **2.9.0+cu130** | **0.0.29.post1** | **0.11.0** | **4.3.0** | ‚úÖ **VALIDATED** |
| 13.0.0 | 2.9.0+cu130 | 0.0.29.post1 | 0.11.0 | 4.3.0 | ‚úÖ **ACCEPTABLE** |
| 12.6 | 2.6.0+cu126 | 0.0.22.post2 | 0.10.0 | 4.1.0 | ‚ö†Ô∏è **DEGRADED** |
| 12.4 | 2.4.1+cu124 | 0.0.22.post2 | 0.9.0 | 3.5.0 | ‚ùå **BLOCKED** |

---

## ‚úÖ **Validation Commands**

**Run before ANY compilation or benchmarking**:
```bash
cd BlackwellSparseK
bash scripts/validate_env.sh

# Expected output:
‚úÖ ENVIRONMENT VALIDATION PASSED

Configuration:
  CUDA:    13.0.2 (nvcc: /usr/local/cuda-13.0/bin/nvcc)
  CUTLASS: v4.3.0 (/opt/cutlass)
  GPU:     NVIDIA H100 80GB HBM3 (CC 9.0)

‚úÖ Safe to proceed with compilation and benchmarking
```

---

**Last Updated**: October 31, 2025  
**Validated On**: NVIDIA H100 80GB HBM3 (sm_90a, CC 9.0)  
**Official Sources**: NVIDIA Documentation (links above)

**For Support**: See [NVIDIA Developer Forums](https://forums.developer.nvidia.com/)

---

## üéØ **Quick Install (Copy-Paste)**

```bash
#!/bin/bash
# BlackwellSparseK Environment Setup
# Run on H100 with Ubuntu 22.04

set -e

# Install CUDA 13.0.2
wget https://developer.download.nvidia.com/compute/cuda/13.0.2/local_installers/cuda_13.0.2_580.95.05_linux.run
sudo sh cuda_13.0.2_580.95.05_linux.run --silent --toolkit --no-opengl-libs

# Install CUTLASS 4.3.0
git clone --branch v4.3.0 https://github.com/NVIDIA/cutlass.git /opt/cutlass

# Set environment
export CUDA_HOME=/usr/local/cuda-13.0
export PATH=/usr/local/cuda-13.0/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:$LD_LIBRARY_PATH
export CUTLASS_HOME=/opt/cutlass
export CPATH=/opt/cutlass/include:$CPATH

# Install Python dependencies
pip install torch --index-url https://download.pytorch.org/whl/nightly/cu130
pip install xformers==0.0.29.post1 vllm==0.11.0 flash-attn>=3.0.0

# Validate
bash scripts/validate_env.sh

echo "‚úÖ Environment ready for BlackwellSparseK compilation"
```

---

**Status**: ‚úÖ **OFFICIAL NVIDIA VERSIONS CONFIRMED**  
**Next**: Install on H100 ‚Üí Compile ‚Üí Benchmark


#!/bin/bash
#
# Expert CUDA Development Environment Setup
# 
# Optimizes PyTorch JIT compilation for fast CUDA kernel iteration.
# Based on expert recommendations for CUDA kernel engineering.
#
# Author: GOATnote Autonomous Research Lab Initiative
# Date: 2025-10-14

set -e

echo "======================================================================="
echo "EXPERT CUDA DEVELOPMENT ENVIRONMENT SETUP"
echo "======================================================================="
echo ""

# Detect GPU architecture
GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1 || echo "Unknown")
echo "üîç Detected GPU: $GPU_NAME"

# Set CUDA architecture based on GPU
if [[ "$GPU_NAME" == *"L4"* ]]; then
    CUDA_ARCH="8.9"
    echo "   Architecture: SM_89 (Ada Lovelace)"
elif [[ "$GPU_NAME" == *"A100"* ]]; then
    CUDA_ARCH="8.0"
    echo "   Architecture: SM_80 (Ampere)"
elif [[ "$GPU_NAME" == *"H100"* ]]; then
    CUDA_ARCH="9.0"
    echo "   Architecture: SM_90 (Hopper)"
else
    CUDA_ARCH="8.9"  # Default to L4
    echo "   ‚ö†Ô∏è  Unknown GPU, defaulting to SM_89"
fi
echo ""

# 1. Install Ninja (fast parallel builds)
echo "üì¶ Installing Ninja build system..."
if command -v ninja &> /dev/null; then
    echo "   ‚úÖ Ninja already installed: $(ninja --version)"
else
    pip install --user ninja
    echo "   ‚úÖ Ninja installed"
fi
echo ""

# 2. Install ccache (optional, for cross-run caching)
echo "üì¶ Checking for ccache (optional)..."
if command -v ccache &> /dev/null; then
    echo "   ‚úÖ ccache available: $(ccache --version | head -1)"
    export NVCC="ccache nvcc"
else
    echo "   ‚ÑπÔ∏è  ccache not installed (optional speedup)"
    echo "      Install with: sudo apt-get install ccache"
fi
echo ""

# 3. Set environment variables
echo "üîß Setting environment variables..."

# Pin to specific GPU architecture (avoid building multiple targets)
export TORCH_CUDA_ARCH_LIST="$CUDA_ARCH"
echo "   TORCH_CUDA_ARCH_LIST=$TORCH_CUDA_ARCH_LIST"

# Use all CPU cores for parallel compilation
export MAX_JOBS=$(nproc)
echo "   MAX_JOBS=$MAX_JOBS"

# Disable incremental builds (can cause issues)
export TORCH_CUDA_INCREMENTAL=0
echo "   TORCH_CUDA_INCREMENTAL=0"

# Verbose build output (for debugging)
# export VERBOSE=1

echo ""

# 4. Create persistent build cache directory
BUILD_CACHE="$HOME/.torch_cuda_cache"
mkdir -p "$BUILD_CACHE"
echo "üìÅ Build cache directory: $BUILD_CACHE"
echo ""

# 5. Export for current session
cat > /tmp/cuda_env_vars.sh << EOF
# Expert CUDA Environment Variables
# Generated by setup_cuda_dev_environment.sh
export TORCH_CUDA_ARCH_LIST="$CUDA_ARCH"
export MAX_JOBS=$(nproc)
export TORCH_CUDA_INCREMENTAL=0
export CUDA_BUILD_CACHE="$BUILD_CACHE"
EOF

echo "üíæ Environment variables saved to: /tmp/cuda_env_vars.sh"
echo "   Source in your shell: source /tmp/cuda_env_vars.sh"
echo ""

# 6. Add to .bashrc (optional)
if [[ -f "$HOME/.bashrc" ]] && ! grep -q "TORCH_CUDA_ARCH_LIST" "$HOME/.bashrc"; then
    read -p "Add to ~/.bashrc permanently? (y/n) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "" >> "$HOME/.bashrc"
        echo "# Expert CUDA Development Environment (added $(date))" >> "$HOME/.bashrc"
        cat /tmp/cuda_env_vars.sh >> "$HOME/.bashrc"
        echo "‚úÖ Added to ~/.bashrc (reload shell to activate)"
    fi
fi
echo ""

# 7. Verify setup
echo "======================================================================="
echo "VERIFICATION"
echo "======================================================================="
echo ""

echo "‚úÖ Python version: $(python3 --version)"
echo "‚úÖ PyTorch version: $(python3 -c 'import torch; print(torch.__version__)')"
echo "‚úÖ CUDA available: $(python3 -c 'import torch; print(torch.cuda.is_available())')"
echo "‚úÖ CUDA version: $(python3 -c 'import torch; print(torch.version.cuda)')"
echo "‚úÖ GPU count: $(python3 -c 'import torch; print(torch.cuda.device_count())')"
echo "‚úÖ GPU name: $(python3 -c 'import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")')"

if command -v ninja &> /dev/null; then
    echo "‚úÖ Ninja: $(which ninja)"
else
    echo "‚ùå Ninja: Not found"
fi

if command -v ccache &> /dev/null; then
    echo "‚úÖ ccache: $(which ccache)"
else
    echo "‚ÑπÔ∏è  ccache: Not installed (optional)"
fi

echo ""
echo "======================================================================="
echo "EXPERT CUDA TOOLKIT: READY"
echo "======================================================================="
echo ""
echo "üöÄ Your environment is optimized for fast CUDA kernel iteration."
echo ""
echo "Next steps:"
echo "  1. Source environment: source /tmp/cuda_env_vars.sh"
echo "  2. Test compilation: python3 cudadent42/bench/fa_s512_tunable.py"
echo "  3. Run Loop 1: python3 cudadent42/bench/loop1_optuna.py"
echo ""
echo "Expected build time: 10-30 seconds (was 3+ minutes)"
echo "======================================================================="

